{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851b3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import gzip\n",
    "\n",
    "from transformers import DPRContextEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoder\n",
    "from transformers import DPRContextEncoder\n",
    "import csv\n",
    "from transformers import BertModel, BertTokenizer, BertTokenizerFast\n",
    "from torch.nn import CosineSimilarity\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from IPython import embed\n",
    "from sklearn.metrics import classification_report\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c5c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, context_file, question_file, idxs):\n",
    "        context_vals = torch.load(context_file) #change these file lines depending on which dataset you want to load from NQ\n",
    "        question_vals = torch.load(question_file)\n",
    "        self.context_embeds = []\n",
    "        for elem in context_vals:\n",
    "            self.context_embeds.append(torch.reshape(elem, (1, 768)))\n",
    "        self.question_embeds = []\n",
    "        for elem in question_vals:\n",
    "            self.question_embeds.append(torch.reshape(elem, (1, 768)))\n",
    "        self.idxs = idxs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_ixs = self.idxs[idx]\n",
    "        query_embed = self.question_embeds[   int(batch_ixs[0])   ]\n",
    "        context_embeds = [ self.context_embeds[int(batch_ixs[i])]  for i in range(len(batch_ixs) -1)  ]\n",
    "        context_embeds[0] = self.context_embeds[ int(batch_ixs[0]) ]\n",
    "        label = idx\n",
    "        return (query_embed, context_embeds, batch_ixs[0:-1], label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b453846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DPR(query_embed, context_embeds, ixs):\n",
    "    similarities = []\n",
    "    for i in range(len(context_embeds)):\n",
    "        similarities.append( torch.dot(query_embed[0], context_embeds[i][0])/torch.norm(context_embeds[i][0]) )\n",
    "        #embed()\n",
    "        #a = normalize(e)\n",
    "        #b = normalize(query_embed)\n",
    "        \n",
    "        #similarities.append( CosineSimilarity(dim=-1, eps=1e-6)(e, query_embed)  )\n",
    "    #embed()\n",
    "    return int(ixs[np.argmax(np.array(similarities))])  #, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f69c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NQ_processing(idx_f):\n",
    "    \n",
    "    rows = []\n",
    "    with open(idx_f, newline='') as idx_file:\n",
    "        for line in csv.reader(idx_file):\n",
    "            rows.append(list(line))\n",
    "    idx_file.close()\n",
    "    return rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20518b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Training Datasets\n",
    "i = 1\n",
    "question_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/train/question-{i}-embeds\"\n",
    "context_file = f\"/home/ubuntu/nlm/williamyang/Data/NQ/train/nq-train-0{i}.jsonl.gz\"\n",
    "idx_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/train/nq-train-ix-{i}.csv\"\n",
    "phrase_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75a2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = NQ_processing(idx_file)\n",
    "dataset = SimpleDataset(context_file, question_file, rows)\n",
    "dataloader = DataLoader(dataset, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52cea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad836c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
