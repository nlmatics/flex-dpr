{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import gzip\n",
    "\n",
    "from transformers import DPRContextEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoder\n",
    "from transformers import DPRContextEncoder\n",
    "import csv\n",
    "from transformers import BertModel, BertTokenizer, BertTokenizerFast\n",
    "from torch.nn import CosineSimilarity\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from IPython import embed\n",
    "from sklearn.metrics import classification_report\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "device = \"cpu\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, context_file, question_file, idxs, NQ, map):\n",
    "        context_vals = torch.load(context_file) \n",
    "        question_vals = torch.load(question_file)\n",
    "        self.context_embeds = []\n",
    "        for elem in context_vals:\n",
    "            self.context_embeds.append(torch.reshape(elem, (1, 768)))\n",
    "        self.query_embeds = []\n",
    "        for elem in question_vals:\n",
    "            self.query_embeds.append(torch.reshape(elem, (1, 768)))\n",
    "        self.ixs = idxs\n",
    "        if not NQ:\n",
    "            self.map = map\n",
    "        else:\n",
    "            self.map = {}\n",
    "            for i in range(len(idxs)):\n",
    "                self.map[str(i)] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ixs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # query embed, context embeds, true label\n",
    "        batch_ixs = self.ixs[idx]\n",
    "        query_embed = self.query_embeds[idx]\n",
    "        context_embeds = [self.context_embeds[int(batch_ixs[i])]  for i in range(len(batch_ixs))  ]\n",
    "        label = batch_ixs[0]\n",
    "        return ( query_embed, context_embeds, batch_ixs[:], label )\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = CosineSimilarity(dim=0, eps=1e-6)\n",
    "def run_DPR(query_embed, context_embeds, ixs):\n",
    "    similarities = []\n",
    "    for i in range(len(context_embeds)):\n",
    "        similarities.append( torch.dot(query_embed[0], context_embeds[i][0])/torch.norm(context_embeds[i][0]) )\n",
    "        #embed()\n",
    "        #a = normalize(e)\n",
    "        #b = normalize(query_embed)\n",
    "        \n",
    "        #similarities.append( CosineSimilarity(dim=-1, eps=1e-6)(e, query_embed)  )\n",
    "    return int(ixs[np.argmax(np.array(similarities))])   #, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NQ_processing(idx_f):\n",
    "    \n",
    "    rows = []\n",
    "    with open(idx_f, newline='') as idx_file:\n",
    "        for line in csv.reader(idx_file):\n",
    "            rows.append(list(line))\n",
    "    idx_file.close()\n",
    "    return rows\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Dev Datasets\n",
    "i = 0\n",
    "question_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/dev/question-{i}-embeds\"\n",
    "context_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/dev/context-{i}-embeds\"\n",
    "idx_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/dev/nq-dev-ix-{i}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Training Datasets\n",
    "i = 0\n",
    "question_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/train/question-{i}-embeds\"\n",
    "context_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/train/context-{i}-embeds\"\n",
    "idx_file = f\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/train/nq-train-ix-{i}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Squad\n",
    "question_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/squad/dev-questions\"\n",
    "context_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/squad/dev-contexts-0\"\n",
    "idx_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/squad/dev_ixs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR PUBMED\n",
    "question_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/pubmed/dev-questions\"\n",
    "context_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/pubmed/dev-contexts-0\"\n",
    "idx_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/pubmed/dev_ixs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR SCOTUS\n",
    "question_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/scotus-flex/dev-questions\"\n",
    "context_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/scotus-flex/dev-contexts-0\"\n",
    "idx_file = \"/home/ubuntu/nlm/noah/scotus/dev_ix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR NFCORPUS\n",
    "question_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/nfcorpus/dev-questions\"\n",
    "context_file = \"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/nfcorpus/dev-contexts-0\"\n",
    "idx_file = \"/home/ubuntu/nlm/noah/nfcorpus/dev-clean-ix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET FOR NQ/PUBMED\n",
    "rows = NQ_processing(idx_file)\n",
    "dataset = SimpleDataset(context_file, question_file, rows, True, [])\n",
    "dataloader = DataLoader(dataset, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET FOR SQUAD\n",
    "rows = NQ_processing(idx_file)\n",
    "file_name = \"/home/ubuntu/nlm/noah/scotus/dev.json\"\n",
    "with open(file_name) as file: \n",
    "    data = json.load(file)\n",
    "QC_map = data['map']\n",
    "dataset = SimpleDataset(context_file, question_file, rows, False, QC_map)\n",
    "dataloader = DataLoader(dataset, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 271/271 [00:00<00:00, 1052.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           3     0.0000    0.0000    0.0000         1\n",
      "           4     0.5000    1.0000    0.6667         1\n",
      "           5     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "           7     0.0000    0.0000    0.0000         1\n",
      "           8     0.0000    0.0000    0.0000         1\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.0000    0.0000    0.0000         1\n",
      "          11     0.0000    0.0000    0.0000         1\n",
      "          12     0.0000    0.0000    0.0000         1\n",
      "          13     0.0000    0.0000    0.0000         1\n",
      "          14     0.0000    0.0000    0.0000         1\n",
      "          15     0.0000    0.0000    0.0000         1\n",
      "          16     0.0000    0.0000    0.0000         1\n",
      "          17     0.0000    0.0000    0.0000         1\n",
      "          18     0.0000    0.0000    0.0000         1\n",
      "          19     0.0000    0.0000    0.0000         1\n",
      "          20     0.0000    0.0000    0.0000         1\n",
      "          21     0.0000    0.0000    0.0000         1\n",
      "          22     0.0000    0.0000    0.0000         1\n",
      "          23     0.0000    0.0000    0.0000         1\n",
      "          24     0.0000    0.0000    0.0000         1\n",
      "          25     0.0000    0.0000    0.0000         1\n",
      "          26     0.0000    0.0000    0.0000         1\n",
      "          27     0.0000    0.0000    0.0000         1\n",
      "          28     0.0000    0.0000    0.0000         1\n",
      "          29     0.0000    0.0000    0.0000         1\n",
      "          30     0.0000    0.0000    0.0000         1\n",
      "          31     0.0000    0.0000    0.0000         1\n",
      "          32     0.0000    0.0000    0.0000         1\n",
      "          33     0.0000    0.0000    0.0000         1\n",
      "          34     0.0000    0.0000    0.0000         1\n",
      "          35     0.0000    0.0000    0.0000         1\n",
      "          36     0.0000    0.0000    0.0000         1\n",
      "          37     0.0000    0.0000    0.0000         1\n",
      "          38     0.0000    0.0000    0.0000         1\n",
      "          39     0.0000    0.0000    0.0000         1\n",
      "          40     0.0000    0.0000    0.0000         1\n",
      "          41     0.0000    0.0000    0.0000         1\n",
      "          42     0.0000    0.0000    0.0000         1\n",
      "          43     0.0000    0.0000    0.0000         1\n",
      "          44     0.0000    0.0000    0.0000         1\n",
      "          45     0.0000    0.0000    0.0000         1\n",
      "          46     0.0000    0.0000    0.0000         1\n",
      "          47     1.0000    1.0000    1.0000         1\n",
      "          48     0.0000    0.0000    0.0000         1\n",
      "          49     0.0000    0.0000    0.0000         1\n",
      "          50     0.0000    0.0000    0.0000         1\n",
      "          51     0.0000    0.0000    0.0000         1\n",
      "          52     0.0000    0.0000    0.0000         1\n",
      "          53     0.0000    0.0000    0.0000         1\n",
      "          54     0.0000    0.0000    0.0000         1\n",
      "          55     0.0000    0.0000    0.0000         1\n",
      "          56     0.0000    0.0000    0.0000         1\n",
      "          57     0.0000    0.0000    0.0000         1\n",
      "          58     0.0000    0.0000    0.0000         1\n",
      "          59     0.0000    0.0000    0.0000         1\n",
      "          60     0.0000    0.0000    0.0000         1\n",
      "          61     0.0000    0.0000    0.0000         1\n",
      "          62     0.0000    0.0000    0.0000         1\n",
      "          63     0.0000    0.0000    0.0000         1\n",
      "          64     0.0000    0.0000    0.0000         1\n",
      "          65     0.0000    0.0000    0.0000         1\n",
      "          66     0.0000    0.0000    0.0000         1\n",
      "          67     0.0000    0.0000    0.0000         1\n",
      "          68     0.0000    0.0000    0.0000         1\n",
      "          69     0.0000    0.0000    0.0000         1\n",
      "          70     0.0000    0.0000    0.0000         1\n",
      "          71     0.0000    0.0000    0.0000         1\n",
      "          72     0.0000    0.0000    0.0000         1\n",
      "          73     0.0000    0.0000    0.0000         1\n",
      "          74     0.0000    0.0000    0.0000         1\n",
      "          75     0.0000    0.0000    0.0000         1\n",
      "          76     0.0000    0.0000    0.0000         1\n",
      "          77     0.2000    1.0000    0.3333         1\n",
      "          78     0.0000    0.0000    0.0000         1\n",
      "          79     0.0000    0.0000    0.0000         1\n",
      "          80     0.0000    0.0000    0.0000         1\n",
      "          81     0.0000    0.0000    0.0000         1\n",
      "          82     0.0000    0.0000    0.0000         1\n",
      "          83     0.0000    0.0000    0.0000         1\n",
      "          84     0.3333    1.0000    0.5000         1\n",
      "          85     0.0000    0.0000    0.0000         1\n",
      "          86     0.0000    0.0000    0.0000         1\n",
      "          87     0.0000    0.0000    0.0000         1\n",
      "          88     0.0000    0.0000    0.0000         1\n",
      "          89     0.2500    1.0000    0.4000         1\n",
      "          90     0.0000    0.0000    0.0000         1\n",
      "          91     0.0000    0.0000    0.0000         1\n",
      "          92     0.0000    0.0000    0.0000         1\n",
      "          93     0.0000    0.0000    0.0000         1\n",
      "          94     0.0455    1.0000    0.0870         1\n",
      "          95     0.0000    0.0000    0.0000         1\n",
      "          96     0.0000    0.0000    0.0000         1\n",
      "          97     0.0000    0.0000    0.0000         1\n",
      "          98     0.0000    0.0000    0.0000         1\n",
      "          99     0.0000    0.0000    0.0000         1\n",
      "         100     0.0000    0.0000    0.0000         1\n",
      "         101     0.0000    0.0000    0.0000         1\n",
      "         102     1.0000    1.0000    1.0000         1\n",
      "         103     0.0000    0.0000    0.0000         1\n",
      "         104     0.0000    0.0000    0.0000         1\n",
      "         105     0.0000    0.0000    0.0000         1\n",
      "         106     0.0000    0.0000    0.0000         1\n",
      "         107     0.0000    0.0000    0.0000         1\n",
      "         108     0.0000    0.0000    0.0000         1\n",
      "         109     0.0000    0.0000    0.0000         1\n",
      "         110     0.0000    0.0000    0.0000         1\n",
      "         111     0.2500    1.0000    0.4000         1\n",
      "         112     0.0000    0.0000    0.0000         1\n",
      "         113     0.0000    0.0000    0.0000         1\n",
      "         114     0.0000    0.0000    0.0000         1\n",
      "         115     0.0000    0.0000    0.0000         1\n",
      "         116     0.0000    0.0000    0.0000         1\n",
      "         117     0.0000    0.0000    0.0000         1\n",
      "         118     0.0000    0.0000    0.0000         1\n",
      "         119     0.0000    0.0000    0.0000         1\n",
      "         120     0.1667    1.0000    0.2857         1\n",
      "         121     0.0000    0.0000    0.0000         1\n",
      "         122     0.0000    0.0000    0.0000         1\n",
      "         123     0.0000    0.0000    0.0000         1\n",
      "         124     0.0000    0.0000    0.0000         1\n",
      "         125     0.0000    0.0000    0.0000         1\n",
      "         126     0.0000    0.0000    0.0000         1\n",
      "         127     0.0000    0.0000    0.0000         1\n",
      "         128     0.0000    0.0000    0.0000         1\n",
      "         129     0.0000    0.0000    0.0000         1\n",
      "         130     0.0000    0.0000    0.0000         1\n",
      "         131     0.0000    0.0000    0.0000         1\n",
      "         132     0.0000    0.0000    0.0000         1\n",
      "         133     0.0000    0.0000    0.0000         1\n",
      "         134     0.0000    0.0000    0.0000         1\n",
      "         135     0.0000    0.0000    0.0000         1\n",
      "         136     0.0000    0.0000    0.0000         1\n",
      "         137     0.0000    0.0000    0.0000         1\n",
      "         138     0.0000    0.0000    0.0000         1\n",
      "         139     1.0000    1.0000    1.0000         1\n",
      "         140     0.0000    0.0000    0.0000         1\n",
      "         141     0.0000    0.0000    0.0000         1\n",
      "         142     0.0000    0.0000    0.0000         1\n",
      "         143     0.0000    0.0000    0.0000         1\n",
      "         144     0.0000    0.0000    0.0000         1\n",
      "         145     0.0000    0.0000    0.0000         1\n",
      "         146     0.0000    0.0000    0.0000         1\n",
      "         147     0.0000    0.0000    0.0000         1\n",
      "         148     0.0000    0.0000    0.0000         1\n",
      "         149     0.0000    0.0000    0.0000         1\n",
      "         150     0.0000    0.0000    0.0000         1\n",
      "         151     0.0000    0.0000    0.0000         1\n",
      "         152     0.0000    0.0000    0.0000         1\n",
      "         153     0.0000    0.0000    0.0000         1\n",
      "         154     0.0000    0.0000    0.0000         1\n",
      "         155     1.0000    1.0000    1.0000         1\n",
      "         156     0.0000    0.0000    0.0000         1\n",
      "         157     0.0000    0.0000    0.0000         1\n",
      "         158     0.0000    0.0000    0.0000         1\n",
      "         159     0.0000    0.0000    0.0000         1\n",
      "         160     0.0000    0.0000    0.0000         1\n",
      "         161     0.0000    0.0000    0.0000         1\n",
      "         162     0.0000    0.0000    0.0000         1\n",
      "         163     0.0000    0.0000    0.0000         1\n",
      "         164     0.0000    0.0000    0.0000         1\n",
      "         165     0.0000    0.0000    0.0000         1\n",
      "         166     0.2500    1.0000    0.4000         1\n",
      "         167     0.0000    0.0000    0.0000         1\n",
      "         168     0.0000    0.0000    0.0000         1\n",
      "         169     0.5000    1.0000    0.6667         1\n",
      "         170     0.0000    0.0000    0.0000         1\n",
      "         171     0.0000    0.0000    0.0000         1\n",
      "         172     0.0000    0.0000    0.0000         1\n",
      "         173     0.0000    0.0000    0.0000         1\n",
      "         174     0.0000    0.0000    0.0000         1\n",
      "         175     0.0000    0.0000    0.0000         1\n",
      "         176     0.0000    0.0000    0.0000         1\n",
      "         177     0.0000    0.0000    0.0000         1\n",
      "         178     0.3333    1.0000    0.5000         1\n",
      "         179     0.0000    0.0000    0.0000         1\n",
      "         180     0.0000    0.0000    0.0000         1\n",
      "         181     0.0000    0.0000    0.0000         1\n",
      "         182     0.1429    1.0000    0.2500         1\n",
      "         183     0.0000    0.0000    0.0000         1\n",
      "         184     0.1429    1.0000    0.2500         1\n",
      "         185     0.0000    0.0000    0.0000         1\n",
      "         186     0.0000    0.0000    0.0000         1\n",
      "         187     0.0000    0.0000    0.0000         1\n",
      "         188     0.0000    0.0000    0.0000         1\n",
      "         189     0.0000    0.0000    0.0000         1\n",
      "         190     0.0000    0.0000    0.0000         1\n",
      "         191     0.0000    0.0000    0.0000         1\n",
      "         192     0.0000    0.0000    0.0000         1\n",
      "         193     0.0000    0.0000    0.0000         1\n",
      "         194     0.0000    0.0000    0.0000         1\n",
      "         195     0.0000    0.0000    0.0000         1\n",
      "         196     0.0000    0.0000    0.0000         1\n",
      "         197     0.0000    0.0000    0.0000         1\n",
      "         198     0.0000    0.0000    0.0000         1\n",
      "         199     0.0000    0.0000    0.0000         1\n",
      "         200     0.0000    0.0000    0.0000         1\n",
      "         201     0.0000    0.0000    0.0000         1\n",
      "         202     0.0000    0.0000    0.0000         1\n",
      "         203     0.0000    0.0000    0.0000         1\n",
      "         204     0.0000    0.0000    0.0000         1\n",
      "         205     0.0000    0.0000    0.0000         1\n",
      "         206     0.0000    0.0000    0.0000         1\n",
      "         207     0.0000    0.0000    0.0000         1\n",
      "         208     0.0000    0.0000    0.0000         1\n",
      "         209     0.0000    0.0000    0.0000         1\n",
      "         210     0.0000    0.0000    0.0000         1\n",
      "         211     0.0000    0.0000    0.0000         1\n",
      "         212     0.0000    0.0000    0.0000         1\n",
      "         213     0.0769    1.0000    0.1429         1\n",
      "         214     0.0000    0.0000    0.0000         1\n",
      "         215     0.0000    0.0000    0.0000         1\n",
      "         216     0.0000    0.0000    0.0000         1\n",
      "         217     0.0000    0.0000    0.0000         1\n",
      "         218     0.0000    0.0000    0.0000         1\n",
      "         219     0.0000    0.0000    0.0000         1\n",
      "         220     0.0000    0.0000    0.0000         1\n",
      "         221     0.0000    0.0000    0.0000         1\n",
      "         222     0.0000    0.0000    0.0000         1\n",
      "         223     0.0000    0.0000    0.0000         1\n",
      "         224     0.0000    0.0000    0.0000         1\n",
      "         225     0.0000    0.0000    0.0000         1\n",
      "         226     0.0000    0.0000    0.0000         1\n",
      "         227     0.0000    0.0000    0.0000         1\n",
      "         228     0.0000    0.0000    0.0000         1\n",
      "         229     0.0000    0.0000    0.0000         1\n",
      "         230     0.0000    0.0000    0.0000         1\n",
      "         231     0.0000    0.0000    0.0000         1\n",
      "         232     0.0000    0.0000    0.0000         1\n",
      "         233     0.0000    0.0000    0.0000         1\n",
      "         234     0.0000    0.0000    0.0000         1\n",
      "         235     0.2000    1.0000    0.3333         1\n",
      "         236     0.0000    0.0000    0.0000         1\n",
      "         237     0.0000    0.0000    0.0000         1\n",
      "         238     0.0000    0.0000    0.0000         1\n",
      "         239     0.0000    0.0000    0.0000         1\n",
      "         240     0.0000    0.0000    0.0000         1\n",
      "         241     0.0000    0.0000    0.0000         1\n",
      "         242     0.0000    0.0000    0.0000         1\n",
      "         243     0.0000    0.0000    0.0000         1\n",
      "         244     0.0000    0.0000    0.0000         1\n",
      "         245     0.0000    0.0000    0.0000         1\n",
      "         246     0.0000    0.0000    0.0000         1\n",
      "         247     0.0227    1.0000    0.0444         1\n",
      "         248     0.0000    0.0000    0.0000         1\n",
      "         249     0.0000    0.0000    0.0000         1\n",
      "         250     0.0000    0.0000    0.0000         1\n",
      "         251     0.0000    0.0000    0.0000         1\n",
      "         252     0.0000    0.0000    0.0000         1\n",
      "         253     0.0000    0.0000    0.0000         1\n",
      "         254     0.0000    0.0000    0.0000         1\n",
      "         255     0.0000    0.0000    0.0000         1\n",
      "         256     0.0000    0.0000    0.0000         1\n",
      "         257     0.0000    0.0000    0.0000         1\n",
      "         258     0.0000    0.0000    0.0000         1\n",
      "         259     0.0000    0.0000    0.0000         1\n",
      "         260     0.0000    0.0000    0.0000         1\n",
      "         261     0.0000    0.0000    0.0000         1\n",
      "         262     0.0000    0.0000    0.0000         1\n",
      "         263     0.0000    0.0000    0.0000         1\n",
      "         264     0.0000    0.0000    0.0000         1\n",
      "         265     0.0000    0.0000    0.0000         1\n",
      "         266     0.0000    0.0000    0.0000         1\n",
      "         267     0.0000    0.0000    0.0000         1\n",
      "         268     0.0000    0.0000    0.0000         1\n",
      "         269     0.0000    0.0000    0.0000         1\n",
      "         270     0.1667    1.0000    0.2857         1\n",
      "\n",
      "    accuracy                         0.0738       271\n",
      "   macro avg     0.0280    0.0738    0.0352       271\n",
      "weighted avg     0.0280    0.0738    0.0352       271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_label = []\n",
    "#BASIC DPR (NO DATALOADER)\n",
    "for i in tqdm(range(len(rows))):\n",
    "    query, context, ixs, label = dataset[i]\n",
    "    pred = run_DPR(query, context, ixs)\n",
    "    # print(\"PRED:\", pred, \"LABEL:\", label)\n",
    "    # print(sims)\n",
    "    y_pred.append(pred)\n",
    "    y_label.append(int(label)) \n",
    "print(classification_report(y_label, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         1\n",
      "\n",
      "    accuracy                         1.0000         1\n",
      "   macro avg     1.0000    1.0000    1.0000         1\n",
      "weighted avg     1.0000    1.0000    1.0000         1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#BASIC DPR \n",
    "\n",
    "y_pred = []\n",
    "y_label = []\n",
    "for step, (query, context, ixs, label) in tqdm(enumerate(dataloader)):\n",
    "    context_embeds = []\n",
    "    # if step == 2: break\n",
    "    for j in range(len(context)):\n",
    "        new = []\n",
    "        for k in range(len(context[j])):\n",
    "            new.append(context[j][k])\n",
    "        context_embeds.append(torch.stack(new))\n",
    "    context_embeds = torch.stack(context_embeds).permute(1,0,2,3)\n",
    "    inds = []\n",
    "    for m in range(len(ixs)):\n",
    "        new = []\n",
    "        for n in range(len(ixs[m])):\n",
    "            new.append(int(ixs[m][n]))\n",
    "        inds.append(new)\n",
    "    inds = torch.tensor(inds).permute(1, 0)    \n",
    "    for i in range(len(query)): # this should be batch size\n",
    "        #embed()\n",
    "        question_embed = query[i] #.detach()\n",
    "        #embed()\n",
    "        pred = run_DPR(question_embed, context_embeds[i], inds[i])\n",
    "        y_pred.append(pred)\n",
    "        y_label.append(int(label[i]))\n",
    "        break\n",
    "    break\n",
    "print(classification_report(y_label, y_pred, digits=4))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.context_embeds[0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Normans The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\\\"Norman\\\" comes from \\\"Norseman\\\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\"\n",
    "with torch.no_grad():\n",
    "    context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')#.to(device)\n",
    "    context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "tokenized = context_tokenizer(s, padding='max_length', max_length = 512,truncation=True)\n",
    "batch_embeds = context_encoder( torch.tensor([tokenized['input_ids']]))[0]\n",
    "print(batch_embeds)\n",
    "vals = torch.load(\"/home/ubuntu/nlm/williamyang/DPR_Preprocess_Data/squad/dev-contexts-0\")\n",
    "print(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM25 \n",
    "\n",
    "def NQ_file_open(file_object, device):\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = json.loads(file_object.readline())\n",
    "            yield chunk\n",
    "        except:\n",
    "            yield \"NONE\"\n",
    "\n",
    "def NQ_get_docs(f):\n",
    "    examples = {'docs': [], 'questions': []}\n",
    "    count = 0\n",
    "    cap = 13000 #number of docs per question set in a dataset\n",
    "    with gzip.open(f, 'r') as file:\n",
    "        for chunk in NQ_file_open(file, device):\n",
    "            if count > cap: \n",
    "                break\n",
    "            if chunk == \"NONE\":\n",
    "                break\n",
    "            examples['questions'].append(chunk['question_text'].split(\" \"))\n",
    "            doc_string = []\n",
    "            for elem in chunk['document_tokens']:\n",
    "                if not elem['html_token']:\n",
    "                    doc_string.append(elem['token'])\n",
    "            examples['docs'].append(doc_string)\n",
    "            count += 1\n",
    "    file.close()\n",
    "    return examples\n",
    "score = 0\n",
    "\n",
    "examples = NQ_get_docs(\"/home/ubuntu/nlm/williamyang/Data/NQ/dev/nq-dev-00.jsonl.gz\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/home/ubuntu/nlm/noah/nfcorpus/dev-clean.json\"\n",
    "with open(file_name) as file: \n",
    "    examples = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NQ_file_open(file_object, device):\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = json.loads(file_object.readline())\n",
    "            yield chunk\n",
    "        except:\n",
    "            yield \"NONE\"\n",
    "\n",
    "f = '/home/ubuntu/nlm/williamyang/Data/NQ/train/nq-train-00.jsonl.gz'\n",
    "examples = {'text': [], 'question': []}\n",
    "count = 0\n",
    "cap = 13000 #number of docs per question set in a dataset\n",
    "with gzip.open(f, 'r') as file:\n",
    "    for chunk in NQ_file_open(file, device):\n",
    "        if count > cap: \n",
    "            break\n",
    "        if chunk == \"NONE\":\n",
    "            break\n",
    "        examples['question'].append(chunk['question_text'].split(\" \"))\n",
    "        doc_string = []\n",
    "        for elem in chunk['document_tokens']:\n",
    "            if not elem['html_token']:\n",
    "                doc_string.append(elem['token'])\n",
    "        examples['text'].append(doc_string)\n",
    "        count += 1\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING SCORING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 2534.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           3     0.0000    0.0000    0.0000         1\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "           5     0.0000    0.0000    0.0000         1\n",
      "           6     0.0000    0.0000    0.0000         1\n",
      "           7     0.0000    0.0000    0.0000         1\n",
      "           8     0.0000    0.0000    0.0000         1\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.0000    0.0000    0.0000         1\n",
      "          11     0.5000    1.0000    0.6667         1\n",
      "          12     0.0000    0.0000    0.0000         1\n",
      "          13     0.0000    0.0000    0.0000         1\n",
      "          14     0.0000    0.0000    0.0000         1\n",
      "          15     0.0000    0.0000    0.0000         1\n",
      "          16     0.0000    0.0000    0.0000         1\n",
      "          17     1.0000    1.0000    1.0000         1\n",
      "          18     0.0000    0.0000    0.0000         1\n",
      "          19     0.0000    0.0000    0.0000         1\n",
      "          20     0.0000    0.0000    0.0000         1\n",
      "          21     1.0000    1.0000    1.0000         1\n",
      "          22     0.0000    0.0000    0.0000         1\n",
      "          23     1.0000    1.0000    1.0000         1\n",
      "          24     0.5000    1.0000    0.6667         1\n",
      "          25     0.5000    1.0000    0.6667         1\n",
      "          26     0.0000    0.0000    0.0000         1\n",
      "          27     0.2000    1.0000    0.3333         1\n",
      "          28     0.3333    1.0000    0.5000         1\n",
      "          29     0.0000    0.0000    0.0000         1\n",
      "          30     0.0000    0.0000    0.0000         1\n",
      "          31     0.0000    0.0000    0.0000         1\n",
      "          32     0.5000    1.0000    0.6667         1\n",
      "          33     1.0000    1.0000    1.0000         1\n",
      "          34     0.0000    0.0000    0.0000         1\n",
      "          35     0.0000    0.0000    0.0000         1\n",
      "          36     0.3333    1.0000    0.5000         1\n",
      "          37     0.0000    0.0000    0.0000         1\n",
      "          38     0.5000    1.0000    0.6667         1\n",
      "          39     1.0000    1.0000    1.0000         1\n",
      "          40     0.0000    0.0000    0.0000         1\n",
      "          41     1.0000    1.0000    1.0000         1\n",
      "          42     0.0000    0.0000    0.0000         1\n",
      "          43     1.0000    1.0000    1.0000         1\n",
      "          44     0.0000    0.0000    0.0000         1\n",
      "          45     0.0000    0.0000    0.0000         1\n",
      "          46     0.0000    0.0000    0.0000         1\n",
      "          47     0.0000    0.0000    0.0000         1\n",
      "          48     0.5000    1.0000    0.6667         1\n",
      "          49     0.0000    0.0000    0.0000         1\n",
      "          50     0.0000    0.0000    0.0000         1\n",
      "          51     0.0000    0.0000    0.0000         1\n",
      "          52     0.5000    1.0000    0.6667         1\n",
      "          53     0.0000    0.0000    0.0000         1\n",
      "          54     0.0000    0.0000    0.0000         1\n",
      "          55     0.5000    1.0000    0.6667         1\n",
      "          56     0.0000    0.0000    0.0000         1\n",
      "          57     0.0000    0.0000    0.0000         1\n",
      "          58     0.0000    0.0000    0.0000         1\n",
      "          59     0.0000    0.0000    0.0000         1\n",
      "          60     0.0000    0.0000    0.0000         1\n",
      "          61     0.0000    0.0000    0.0000         1\n",
      "          62     0.0000    0.0000    0.0000         1\n",
      "          63     0.0000    0.0000    0.0000         1\n",
      "          64     0.0000    0.0000    0.0000         1\n",
      "          65     0.0000    0.0000    0.0000         1\n",
      "          66     0.0000    0.0000    0.0000         1\n",
      "          67     0.0000    0.0000    0.0000         1\n",
      "          68     0.0000    0.0000    0.0000         1\n",
      "          69     0.0000    0.0000    0.0000         1\n",
      "          70     0.3333    1.0000    0.5000         1\n",
      "          71     0.5000    1.0000    0.6667         1\n",
      "          72     0.0000    0.0000    0.0000         1\n",
      "          73     0.0000    0.0000    0.0000         1\n",
      "          74     0.0000    0.0000    0.0000         1\n",
      "          75     1.0000    1.0000    1.0000         1\n",
      "          76     1.0000    1.0000    1.0000         1\n",
      "          77     0.0000    0.0000    0.0000         1\n",
      "          78     0.5000    1.0000    0.6667         1\n",
      "          79     1.0000    1.0000    1.0000         1\n",
      "          80     0.0000    0.0000    0.0000         1\n",
      "          81     0.0000    0.0000    0.0000         1\n",
      "          82     0.3333    1.0000    0.5000         1\n",
      "          83     0.0000    0.0000    0.0000         1\n",
      "          84     1.0000    1.0000    1.0000         1\n",
      "          85     0.0000    0.0000    0.0000         1\n",
      "          86     0.0000    0.0000    0.0000         1\n",
      "          87     0.5000    1.0000    0.6667         1\n",
      "          88     0.0000    0.0000    0.0000         1\n",
      "          89     0.0000    0.0000    0.0000         1\n",
      "          90     1.0000    1.0000    1.0000         1\n",
      "          91     0.0000    0.0000    0.0000         1\n",
      "          92     0.0000    0.0000    0.0000         1\n",
      "          93     1.0000    1.0000    1.0000         1\n",
      "          94     0.0000    0.0000    0.0000         1\n",
      "          95     1.0000    1.0000    1.0000         1\n",
      "          96     0.5000    1.0000    0.6667         1\n",
      "          97     0.0000    0.0000    0.0000         1\n",
      "          98     0.0000    0.0000    0.0000         1\n",
      "          99     0.3333    1.0000    0.5000         1\n",
      "         100     1.0000    1.0000    1.0000         1\n",
      "         101     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.3235       102\n",
      "   macro avg     0.2242    0.3235    0.2533       102\n",
      "weighted avg     0.2242    0.3235    0.2533       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#bm25 = BM25Okapi([word_tokenize(a) for a in examples['text']])\n",
    "bm25 = BM25Okapi([word_tokenize(a) for a in examples['text']])\n",
    "print(\"STARTING SCORING\")\n",
    "y_pred = []\n",
    "y_label = []\n",
    "for i in tqdm(range(len(examples['question']))):\n",
    "    tokenized_query = examples['question'][i]\n",
    "    doc_scores = bm25.get_scores(word_tokenize(tokenized_query))\n",
    "    y_pred.append(np.argmax(doc_scores))\n",
    "    y_label.append(examples['map'][str(i)])\n",
    "    #y_label.append(i)\n",
    "    # if label == pred: score += 1\n",
    "    # print(\"PRED: \", pred)\n",
    "    # print(\"LABEL: \", label)\n",
    "print(classification_report(y_label, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'purpose', 'did', 'seasonal', 'monsoon', 'winds', 'have', 'on', 'trade']\n"
     ]
    }
   ],
   "source": [
    "print(examples['question'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
